{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169e24db",
   "metadata": {},
   "source": [
    "<font size=6>**TD 2 : classification supervisée**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e29c8",
   "metadata": {},
   "source": [
    "Ce notebook est un exemple de traitement des données textuelles à des fins de classification binaires (2 classes uniquement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb8284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499b15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraires utilisées\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# différents classifieurs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dead880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour ignorer les avertissements\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f85be",
   "metadata": {},
   "source": [
    "# chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d59e6",
   "metadata": {},
   "source": [
    "Chargement des données à partir d'un fichier .csv (colonnes séparées par une tabulation = \"\\t\").\n",
    "\n",
    "Nous allons utiliser, pour la démonstration, un jeu de données contenant des propos toxiques diffusés sur Internet (cf. défi Kaggle de 2018 : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n",
    "\n",
    "**Attention :** certains propos tenus dans les données peuvent choquer (insultes, racisme, etc.). Si vous le préferez, rien ne vous oblige à aller lire les textes d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe80481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load = pd.read_csv(\"https://raw.githubusercontent.com/upunaprosk/ul2-nlp-course/refs/heads/2024/TD2/toxic_10k.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68069f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_load.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2420a56",
   "metadata": {},
   "source": [
    "Affichage d'un extrait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edb192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>textes</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>83838</td>\n",
       "      <td>I'm afraid I know little about taxonomy, so ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>79900</td>\n",
       "      <td>Talk:Jerusalem   Hi, I would appreciate it if ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>119587</td>\n",
       "      <td>Explanation   OTRS is for the people who have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>86719</td>\n",
       "      <td>friends' suspicions   The article says: Schiav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>92604</td>\n",
       "      <td>\"I don't know anyone who has entertained the b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ids                                             textes  classes\n",
       "9995   83838  I'm afraid I know little about taxonomy, so ha...        0\n",
       "9996   79900  Talk:Jerusalem   Hi, I would appreciate it if ...        0\n",
       "9997  119587  Explanation   OTRS is for the people who have ...        0\n",
       "9998   86719  friends' suspicions   The article says: Schiav...        0\n",
       "9999   92604  \"I don't know anyone who has entertained the b...        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on préfère affiche des exemples non toxiques, situés à la fin\n",
    "data_load.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2770971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "textes = data_load[\"textes\"]\n",
    "classes = data_load[\"classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c6c82",
   "metadata": {},
   "source": [
    "Distribution des valeurs pour la classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d730ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 occurs 5000 times\n",
      "1 occurs 5000 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(classes, return_counts=True)\n",
    "\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value} occurs {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d3e25",
   "metadata": {},
   "source": [
    "# Mise en forme des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c8ce5",
   "metadata": {},
   "source": [
    "Construction de la matrice Documents x Termes (cf. TP précédent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283f35",
   "metadata": {},
   "source": [
    "## Tâche : Vectorisation de textes avec TF-IDF\n",
    "\n",
    "L'objectif de cette tâche est de transformer un corpus de documents textuels en une matrice de caractéristiques TF-IDF. Cela consiste à utiliser le `TfidfVectorizer` de la bibliothèque `sklearn` pour mesurer l'importance des mots et des paires de mots (unigrammes et bigrammes) dans le corpus.\n",
    "\n",
    "Documentation: https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde52120",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(...) # YOUR Code\n",
    "vectorize.fit(textes)\n",
    "data = vectorize.transform(textes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797838d7",
   "metadata": {},
   "source": [
    "Division du jeu de données initial en deux sous-ensembles :\n",
    "\n",
    "- données d'entraînement ou *training set*\n",
    "- données de test (ici appelé parfois valiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1687b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain_X, subtest_X, subtrain_y, subtest_y = train_test_split(data, classes,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                   stratify=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c9afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement : 0:3500 1:3500\n",
      "Jeu de test : 0:1500 1:1500\n"
     ]
    }
   ],
   "source": [
    "# vérifions que la stratification a bien fonctionné\n",
    "\n",
    "unique_values_a, counts_a = np.unique(subtrain_y, return_counts=True)\n",
    "unique_values_b, counts_b = np.unique(subtest_y, return_counts=True)\n",
    "\n",
    "print(f\"Jeu d'entrainement : \" + \" \".join([f\"{value}:{count}\" for value, count in zip(unique_values_a, counts_a)]))\n",
    "print(f\"Jeu de test : \" + \" \".join([f\"{value}:{count}\" for value, count in zip(unique_values_b, counts_b)]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af41d6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 18725)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtrain_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168c5a6",
   "metadata": {},
   "source": [
    "# Apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c771ce4",
   "metadata": {},
   "source": [
    "Nous allons tester différents algorithmes de classification supervisée qui traitent ici les textes en suivant l'hypothèse du sac de mots (BoW)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a34815",
   "metadata": {},
   "source": [
    "## Simple régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c352768",
   "metadata": {},
   "source": [
    "## Tâche : Classification avec régression logistique\n",
    "\n",
    "L'objectif de cette tâche est d'effectuer une classification en utilisant un modèle de régression logistique. Il s'agit d'entraîner le modèle sur un sous-ensemble de données d'entraînement et de prédire les étiquettes sur un sous-ensemble de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8da01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = YOUR Code\n",
    "\n",
    "lr.fit(subtrain_X, subtrain_y)\n",
    "pred_y_lr = lr.predict(subtest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2284e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce qui est prédit : [1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1]\n",
      "La vérité : 1370    1\n",
      "2240    1\n",
      "8581    0\n",
      "2338    1\n",
      "2929    1\n",
      "3212    1\n",
      "1583    1\n",
      "5728    0\n",
      "3049    1\n",
      "7613    0\n",
      "9233    0\n",
      "3658    1\n",
      "5692    0\n",
      "3413    1\n",
      "4198    1\n",
      "128     1\n",
      "898     1\n",
      "4264    1\n",
      "7611    0\n",
      "505     1\n",
      "Name: classes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Ce qui est prédit : \" + str(pred_y_lr[0:20]))\n",
    "\n",
    "print(\"La vérité : \" + str(subtest_y[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ea40b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réussite en validation 86.2%\n"
     ]
    }
   ],
   "source": [
    "res_test = np.sum(pred_y_lr == subtest_y) / float(len(subtest_y))\n",
    "                                       \n",
    "print(f\"Réussite en validation {res_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1db81",
   "metadata": {},
   "source": [
    "A comparer à la réussite sur le jeu d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61e9db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réussite sur les données d'entraînement 93.6%\n"
     ]
    }
   ],
   "source": [
    "pred_y_lr = lr.predict(subtrain_X)\n",
    "\n",
    "res_train = np.sum(pred_y_lr == subtrain_y) / float(len(subtrain_y))\n",
    "print(f\"Réussite sur les données d'entraînement {res_train:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3d0b7",
   "metadata": {},
   "source": [
    "Deux remarques importantes à ce stade :\n",
    "\n",
    "    1. On peut observer une différence entre les deux erreurs, signe d'un sur-apprentissage (*overfitting*)\n",
    "    2. Nous avons utilisé un même nom de variable (pred_y_lr) pour deux résultats différents : c'est une mauvaise habitude et nous allons utiliser 2 variables différentes pour la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc343b",
   "metadata": {},
   "source": [
    "Concernant le sur-apprentissage, une piste serait ici de régulariser le modèle avec un terme qui pénalise une trop grande dispersion des poids (régression ridge et lasso).\n",
    "Essayons par ex. la régression ridge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc5ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ridge = RidgeClassifier(alpha=20.0)\n",
    "lr_ridge.fit(subtrain_X, subtrain_y)\n",
    "pred_train_lr_ridge = lr_ridge.predict(subtrain_X)\n",
    "pred_test_lr_ridge = lr_ridge.predict(subtest_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffeb084",
   "metadata": {},
   "source": [
    "Le paramètre *alpha* indique la force de la régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392accff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réussite (accuracy) sur :\n",
      "  - ensemble d'entraînement : 88.6%\n",
      "  - ensemble de test : 83.9%\n"
     ]
    }
   ],
   "source": [
    "res_train = np.sum(pred_train_lr_ridge == subtrain_y) / float(len(subtrain_y))\n",
    "res_test = np.sum(pred_test_lr_ridge == subtest_y) / float(len(subtest_y))\n",
    "\n",
    "print(f\"Réussite (accuracy) sur :\")\n",
    "print(f\"  - ensemble d'entraînement : {res_train:.1%}\")\n",
    "print(f\"  - ensemble de test : {res_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e145ab",
   "metadata": {},
   "source": [
    "On constate qu'on diminue le sur-apprentissage, mais au prix d'une réussite plus faible..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6000f",
   "metadata": {},
   "source": [
    "## Une évaluation plus robuste : la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48affcec",
   "metadata": {},
   "source": [
    "Il s'agit ici d'évaluation la capacité de l'algorithme choisi à résoudre la tâche de classification.\n",
    "L'objectif est donc plus de choisir l'algorithme que de trouver le modèle lui-même."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cfc99",
   "metadata": {},
   "source": [
    "### Tâche\n",
    "\n",
    "Utilisez la validation croisée par k-fold pour évaluer votre modèle. Créez un objet `KFold` avec les paramètres suivants :\n",
    "- **n_splits** : 10 (nombre de sous-ensembles dans lesquels les données seront divisées).\n",
    "- **shuffle** : True (pour mélanger les données avant de les diviser).\n",
    "- **random_state** : une valeur fixe pour garantir la reproductibilité (utilisez la variable `seed` à cet effet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16e1718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation croisée : moyenne 86.5% et écart-type 0.01\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# kfold = YOUR Code\n",
    "\n",
    "results = cross_val_score(lr, subtrain_X, subtrain_y, cv=kfold)\n",
    "print(f\"Validation croisée : moyenne {results.mean():.1%} et écart-type {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040a9dd",
   "metadata": {},
   "source": [
    "Une fois l'algorithme choisi, il s'agit de réentraîner le modèle sur l'ensemble des données d'entraînement (cf. 3.1).\n",
    "\n",
    "Pour simplifier le code, on crée une fonction d'affichage des deux erreurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d04eba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(nom_algo, pred_train, pred_test):\n",
    "    print(nom_algo + \" : \")\n",
    "    acc_app = np.sum(pred_train == subtrain_y) / float(len(subtrain_y))\n",
    "    print(f\"  - réussite (accuracy) apparente : {acc_app:.1%}\")\n",
    "    acc_gen = np.sum(pred_test == subtest_y) / float(len(subtest_y))\n",
    "    print(f\"  - réussite (accuracy) en généralisation : {acc_gen:.1%}\")                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4fc52",
   "metadata": {},
   "source": [
    "## Machines à vecteurs supports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169723a",
   "metadata": {},
   "source": [
    "### Tâche\n",
    "\n",
    "Implémentez un classificateur SVM (Support Vector Machine) avec un noyau linéaire. Créez un objet `SVC` avec les paramètres suivants :\n",
    "- **kernel** : \"linear\" (utilisez un noyau linéaire pour la classification).\n",
    "- **degree** : 1 (ce paramètre est sans effet pour un noyau linéaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdac577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC linéaire : \n",
      "  - réussite (accuracy) apparente : 97.6%\n",
      "  - réussite (accuracy) en généralisation : 87.4%\n"
     ]
    }
   ],
   "source": [
    "svc_lin = SVC(...) # YOUR Code\n",
    "\n",
    "svc_lin.fit(subtrain_X, subtrain_y)\n",
    "\n",
    "pred_train_svc_lin = svc_lin.predict(subtrain_X)\n",
    "pred_test_svc_lin = svc_lin.predict(subtest_X)\n",
    "\n",
    "print_accuracy(\"SVC linéaire\", pred_train_svc_lin, pred_test_svc_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708757bf",
   "metadata": {},
   "source": [
    "Créez un classificateur SVM avec un noyau polynomial. Utilisez `SVC` avec les paramètres suivants :\n",
    "- **kernel** : \"poly\"\n",
    "- **degree** : 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f030b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC poly degré 2 : \n",
      "  - réussite (accuracy) apparente : 99.8%\n",
      "  - réussite (accuracy) en généralisation : 85.9%\n"
     ]
    }
   ],
   "source": [
    "svc_poly2 = SVC(...) # YOUR Code\n",
    "\n",
    "svc_poly2.fit(subtrain_X, subtrain_y)\n",
    "\n",
    "pred_train_svc_poly2 = svc_poly2.predict(subtrain_X)\n",
    "pred_test_svc_poly2 = svc_poly2.predict(subtest_X)\n",
    "\n",
    "print_accuracy(\"SVC poly degré 2\", pred_train_svc_poly2, pred_test_svc_poly2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e0170",
   "metadata": {},
   "source": [
    "## Arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25f06511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost : \n",
      "  - réussite (accuracy) apparente : 94.7%\n",
      "  - réussite (accuracy) en généralisation : 86.0%\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(verbosity=0)\n",
    "\n",
    "xgb.fit(subtrain_X, subtrain_y)\n",
    "\n",
    "pred_train_xgb = xgb.predict(subtrain_X)\n",
    "pred_test_xgb = xgb.predict(subtest_X)\n",
    "\n",
    "print_accuracy(\"XGBoost\", pred_train_xgb, pred_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16250ab",
   "metadata": {},
   "source": [
    "## Réseau de neurones simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a541f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 1 couche cachée : \n",
      "  - réussite (accuracy) apparente : 99.9%\n",
      "  - réussite (accuracy) en généralisation : 86.6%\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3), random_state=1)\n",
    "\n",
    "mlp.fit(subtrain_X, subtrain_y)\n",
    "\n",
    "pred_train_mlp = mlp.predict(subtrain_X)\n",
    "pred_test_mlp = mlp.predict(subtest_X)\n",
    "\n",
    "print_accuracy(\"MLP 1 couche cachée\", pred_train_mlp, pred_test_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b8755",
   "metadata": {},
   "source": [
    "# Affichage des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce10f6",
   "metadata": {},
   "source": [
    "Il faut créer une table qui résume les principaux résultats obtenus.\n",
    "Ici, on se contentera d'utiliser la pertinence (*accuracy*) des résultats, mais d'autres critères pourraient être employés : temps d'apprentissage, temps pour l'inférence, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3a7890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction qui retourne les scores d'erreur\n",
    "def get_accuracy(pred_train, pred_test):\n",
    "    acc_app = np.sum(pred_train == subtrain_y) / float(len(subtrain_y))\n",
    "    acc_gen = np.sum(pred_test == subtest_y) / float(len(subtest_y))\n",
    "    return acc_app, acc_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f6a3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des réussites (accuracy)\n",
    "\n",
    "pred_train_lr = lr.predict(subtrain_X)\n",
    "pred_test_lr = lr.predict(subtest_X)\n",
    "acc_train_lr, acc_test_lr = get_accuracy(pred_train_lr, pred_test_lr)\n",
    "pred_train_lr_ridge = lr_ridge.predict(subtrain_X)\n",
    "pred_test_lr_ridge = lr_ridge.predict(subtest_X)\n",
    "acc_train_lr_ridge, acc_test_lr_ridge = get_accuracy(pred_train_lr_ridge, pred_test_lr_ridge)\n",
    "acc_train_svc_lin, acc_test_svc_lin = get_accuracy(pred_train_svc_lin, pred_test_svc_lin)\n",
    "acc_train_svc_poly2, acc_test_svc_poly2 = get_accuracy(pred_train_svc_poly2, pred_test_svc_poly2)\n",
    "acc_train_xgb, acc_test_xgb = get_accuracy(pred_train_xgb, pred_test_xgb)\n",
    "acc_train_mlp, acc_test_mlp = get_accuracy(pred_train_mlp, pred_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2b097c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noms_algo = [\"Régression logistique\", \"Classification Ridge\", \"SVM linéaire\", \"SVM polynôme 2\", \"XGBoost\", \"MLP 1 couche cachée\"]\n",
    "acc_app = [acc_train_lr, acc_train_lr_ridge, acc_train_svc_lin, acc_train_svc_poly2, acc_train_xgb, acc_train_mlp]\n",
    "acc_gen = [acc_test_lr, acc_test_lr_ridge, acc_test_svc_lin, acc_test_svc_poly2, acc_test_xgb, acc_test_mlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "288b25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({\"algo\" : noms_algo, \"accuracy app\": acc_app, \"accuracy gen\": acc_gen})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aac7c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_840a1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_840a1_level0_col0\" class=\"col_heading level0 col0\" >algo</th>\n",
       "      <th id=\"T_840a1_level0_col1\" class=\"col_heading level0 col1\" >accuracy app</th>\n",
       "      <th id=\"T_840a1_level0_col2\" class=\"col_heading level0 col2\" >accuracy gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_840a1_row0_col0\" class=\"data row0 col0\" >Régression logistique</td>\n",
       "      <td id=\"T_840a1_row0_col1\" class=\"data row0 col1\" >93.64%</td>\n",
       "      <td id=\"T_840a1_row0_col2\" class=\"data row0 col2\" >86.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_840a1_row1_col0\" class=\"data row1 col0\" >Classification Ridge</td>\n",
       "      <td id=\"T_840a1_row1_col1\" class=\"data row1 col1\" >88.57%</td>\n",
       "      <td id=\"T_840a1_row1_col2\" class=\"data row1 col2\" >83.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_840a1_row2_col0\" class=\"data row2 col0\" >SVM linéaire</td>\n",
       "      <td id=\"T_840a1_row2_col1\" class=\"data row2 col1\" >97.60%</td>\n",
       "      <td id=\"T_840a1_row2_col2\" class=\"data row2 col2\" >87.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_840a1_row3_col0\" class=\"data row3 col0\" >SVM polynôme 2</td>\n",
       "      <td id=\"T_840a1_row3_col1\" class=\"data row3 col1\" >99.76%</td>\n",
       "      <td id=\"T_840a1_row3_col2\" class=\"data row3 col2\" >85.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_840a1_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
       "      <td id=\"T_840a1_row4_col1\" class=\"data row4 col1\" >94.69%</td>\n",
       "      <td id=\"T_840a1_row4_col2\" class=\"data row4 col2\" >86.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_840a1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_840a1_row5_col0\" class=\"data row5 col0\" >MLP 1 couche cachée</td>\n",
       "      <td id=\"T_840a1_row5_col1\" class=\"data row5 col1\" >99.94%</td>\n",
       "      <td id=\"T_840a1_row5_col2\" class=\"data row5 col2\" >86.57%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a0ce10b670>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.style.format({\n",
    "    \"accuracy app\": '{:,.2%}'.format,\n",
    "    \"accuracy gen\": '{:,.2%}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f83064",
   "metadata": {},
   "source": [
    "On constate ici que le meilleur classifieur est linéaires. Plusieurs explications sont possibles :\n",
    "\n",
    "- Le problème est très simple et un classifieur linéaire suffit à obtenir de (très) bonnes performances\n",
    "- L'ensemble de test n'est pas très représentatif et ressemble trop aux données d'entraînement (biais dans l'acquisition des données)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286d3dd",
   "metadata": {},
   "source": [
    "L'écart entre la réussite apparente (ie calculée sur les données d'entraînement) et la réussite en généralisation (ie calculées sur les données test) reflète le phénomène de sur-apprentissage ou *overfitting*.\n",
    "\n",
    "Cela peut nous aider à mieux mettre au point les classifieurs, mais c'est bien la réussite en généralisation qui guide le classifieur qui sera finalement choisi."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
